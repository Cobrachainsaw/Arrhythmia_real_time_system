{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import json\n",
    "from mealpy.evolutionary_based.GA import BaseGA\n",
    "from mealpy.evolutionary_based import GA\n",
    "from mealpy import FloatVar\n",
    "from mealpy import IntegerVar\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('C:/Users/vinay/Downloads/mit-bih-arrhythmia-database-1.0.0/mit-bih-arrhythmia-database-1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files=[]\n",
    "annot_files=[]\n",
    "for file in os.listdir(file_path):\n",
    "    if('.dat' in file):\n",
    "        data_files.append(file[:-4])\n",
    "    elif('.atr' in file):\n",
    "        annot_files.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+': 0, 'N': 1, 'A': 2, 'V': 3, '~': 4, '|': 5, 'Q': 6, '/': 7, 'f': 8, 'x': 9, 'F': 10, 'j': 11, 'L': 12, 'a': 13, 'J': 14, 'R': 15, '[': 16, '!': 17, ']': 18, 'E': 19, 'S': 20, '\"': 21, 'e': 22}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {}\n",
    "count = 0 \n",
    "\n",
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr') \n",
    "    \n",
    "    for symbol in annotation.symbol:\n",
    "        if symbol not in char_to_int: \n",
    "            char_to_int[symbol] = count\n",
    "            count += 1 \n",
    "\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'+': 1, 'A': 33, 'N': 2239, 'V': 1} 2274 2274\n",
      "101 {'+': 1, 'A': 3, 'N': 1860, 'Q': 2, '|': 4, '~': 4} 1874 1874\n",
      "102 {'+': 5, '/': 2028, 'N': 99, 'V': 4, 'f': 56} 2192 2192\n",
      "103 {'+': 1, 'A': 2, 'N': 2082, '~': 6} 2091 2091\n",
      "104 {'+': 45, '/': 1380, 'N': 163, 'Q': 18, 'V': 2, 'f': 666, '~': 37} 2311 2311\n",
      "105 {'+': 1, 'N': 2526, 'Q': 5, 'V': 41, '|': 30, '~': 88} 2691 2691\n",
      "106 {'+': 41, 'N': 1507, 'V': 520, '~': 30} 2098 2098\n",
      "107 {'+': 1, '/': 2078, 'V': 59, '~': 2} 2140 2140\n",
      "108 {'+': 1, 'A': 4, 'F': 2, 'N': 1739, 'V': 17, 'j': 1, 'x': 11, '|': 8, '~': 41} 1824 1824\n",
      "109 {'+': 1, 'F': 2, 'L': 2492, 'V': 38, '~': 2} 2535 2535\n",
      "111 {'+': 1, 'L': 2123, 'V': 1, '~': 8} 2133 2133\n",
      "112 {'+': 1, 'A': 2, 'N': 2537, '~': 10} 2550 2550\n",
      "113 {'+': 1, 'N': 1789, 'a': 6} 1796 1796\n",
      "114 {'+': 3, 'A': 10, 'F': 4, 'J': 2, 'N': 1820, 'V': 43, '|': 1, '~': 7} 1890 1890\n",
      "115 {'+': 1, 'N': 1953, '|': 6, '~': 2} 1962 1962\n",
      "116 {'+': 1, 'A': 1, 'N': 2302, 'V': 109, '~': 8} 2421 2421\n",
      "117 {'+': 1, 'A': 1, 'N': 1534, '~': 3} 1539 1539\n",
      "118 {'+': 1, 'A': 96, 'R': 2166, 'V': 16, 'x': 10, '~': 12} 2301 2301\n",
      "119 {'+': 103, 'N': 1543, 'V': 444, '~': 4} 2094 2094\n",
      "121 {'+': 1, 'A': 1, 'N': 1861, 'V': 1, '~': 12} 1876 1876\n",
      "122 {'+': 1, 'N': 2476, '|': 2} 2479 2479\n",
      "123 {'+': 1, 'N': 1515, 'V': 3} 1519 1519\n",
      "124 {'+': 13, 'A': 2, 'F': 5, 'J': 29, 'R': 1531, 'V': 47, 'j': 5, '~': 2} 1634 1634\n",
      "200 {'+': 148, 'A': 30, 'F': 2, 'N': 1743, 'V': 826, '~': 43} 2792 2792\n",
      "201 {'+': 35, 'A': 30, 'F': 2, 'J': 1, 'N': 1625, 'V': 198, 'a': 97, 'j': 10, 'x': 37, '~': 4} 2039 2039\n",
      "202 {'+': 8, 'A': 36, 'F': 1, 'N': 2061, 'V': 19, 'a': 19, '|': 2} 2146 2146\n",
      "203 {'+': 45, 'F': 1, 'N': 2529, 'Q': 4, 'V': 444, 'a': 2, '|': 26, '~': 57} 3108 3108\n",
      "205 {'+': 13, 'A': 3, 'F': 11, 'N': 2571, 'V': 71, '|': 1, '~': 2} 2672 2672\n",
      "207 {'!': 472, '+': 24, 'A': 107, 'E': 105, 'L': 1457, 'R': 86, 'V': 105, '[': 6, ']': 6, '|': 2, '~': 15} 2385 2385\n",
      "208 {'+': 53, 'F': 373, 'N': 1586, 'Q': 2, 'S': 2, 'V': 992, '|': 8, '~': 24} 3040 3040\n",
      "209 {'+': 21, 'A': 383, 'N': 2621, 'V': 1, '|': 7, '~': 19} 3052 3052\n",
      "210 {'+': 17, 'E': 1, 'F': 10, 'N': 2423, 'V': 194, 'a': 22, '|': 1, '~': 17} 2685 2685\n",
      "212 {'+': 1, 'N': 923, 'R': 1825, '|': 1, '~': 13} 2763 2763\n",
      "213 {'+': 43, 'A': 25, 'F': 362, 'N': 2641, 'V': 220, 'a': 3} 3294 3294\n",
      "214 {'\"': 1, '+': 25, 'F': 1, 'L': 2003, 'Q': 2, 'V': 256, '|': 5, '~': 4} 2297 2297\n",
      "215 {'\"': 2, '+': 5, 'A': 3, 'F': 1, 'N': 3195, 'V': 164, '~': 30} 3400 3400\n",
      "217 {'+': 67, '/': 1542, 'N': 244, 'V': 162, 'f': 260, '|': 1, '~': 4} 2280 2280\n",
      "219 {'\"': 4, '+': 21, 'A': 7, 'F': 1, 'N': 2082, 'V': 64, 'x': 133} 2312 2312\n",
      "220 {'+': 17, 'A': 94, 'N': 1954, '~': 4} 2069 2069\n",
      "221 {'+': 23, 'N': 2031, 'V': 396, '~': 12} 2462 2462\n",
      "222 {'+': 136, 'A': 208, 'J': 1, 'N': 2062, 'j': 212, '~': 15} 2634 2634\n",
      "223 {'+': 28, 'A': 72, 'F': 14, 'N': 2029, 'V': 473, 'a': 1, 'e': 16, '~': 10} 2643 2643\n",
      "228 {'\"': 3, '+': 41, 'A': 3, 'N': 1688, 'V': 362, '|': 24, '~': 20} 2141 2141\n",
      "230 {'+': 207, 'N': 2255, 'V': 1, '|': 1, '~': 2} 2466 2466\n",
      "231 {'\"': 427, '+': 11, 'A': 1, 'N': 314, 'R': 1254, 'V': 2, 'x': 2} 2011 2011\n",
      "232 {'+': 1, 'A': 1382, 'R': 397, 'j': 1, '~': 35} 1816 1816\n",
      "233 {'+': 71, 'A': 7, 'F': 11, 'N': 2230, 'V': 831, '|': 2} 3152 3152\n",
      "234 {'+': 3, 'J': 50, 'N': 2700, 'V': 3, '~': 8} 2764 2764\n"
     ]
    }
   ],
   "source": [
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr')\n",
    "    unique, counts = np.unique(annotation.symbol, return_counts=True)\n",
    "    print(file, dict(zip(unique, counts)), counts.sum(), len(annotation.sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(48):\n",
    "    data, field = wfdb.rdsamp(os.path.join(file_path, data_files[i]))\n",
    "    data = data[:, 0]\n",
    "    \n",
    "    annot = wfdb.rdann(os.path.join(file_path, annot_files[i]), 'atr')\n",
    "    segmented_signals = [data[max(0, peak - 100):min(len(data), peak + 100)] for peak in annot.sample]\n",
    "    \n",
    "    segmented_array = np.array([\n",
    "        np.pad(signal, (0, 200 - len(signal)), mode='edge') if len(signal) < 200 else signal\n",
    "        for signal in segmented_signals\n",
    "    ])\n",
    "    \n",
    "    labels = annot.symbol[:len(segmented_array)]  \n",
    "\n",
    "    all_signals.append(segmented_array)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_X_train, f_X_test, f_y_train, f_y_test = [], [], [], []\n",
    "for i in range(48):\n",
    "    X = np.array(all_signals[i]).reshape(-1, 200)\n",
    "    y = np.array(all_labels[i]).flatten()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=42\n",
    "    )\n",
    "    f_X_train.append(X_train)\n",
    "    f_X_test.append(X_test)\n",
    "    f_y_train.extend(y_train)  \n",
    "    f_y_test.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Shape: (84470, 200, 1), Test Shape: (28177, 200, 1)\n",
      "Final Train Labels Shape: (84470, 23), Test Labels Shape: (28177, 23)\n"
     ]
    }
   ],
   "source": [
    "f_X_train = np.vstack(f_X_train).reshape(-1, 200, 1)\n",
    "f_X_test = np.vstack(f_X_test).reshape(-1, 200, 1)\n",
    "y_train_int = [char_to_int.get(char, -1) for char in f_y_train]\n",
    "y_test_int = [char_to_int.get(char, -1) for char in f_y_test]\n",
    "y_train_int = [y for y in y_train_int if y != -1]\n",
    "y_test_int = [y for y in y_test_int if y != -1]\n",
    "num_classes = len(char_to_int)\n",
    "f_y_train = to_categorical(y_train_int, num_classes=num_classes)\n",
    "f_y_test = to_categorical(y_test_int, num_classes=num_classes)\n",
    "print(f\"Final Train Shape: {f_X_train.shape}, Test Shape: {f_X_test.shape}\")\n",
    "print(f\"Final Train Labels Shape: {f_y_train.shape}, Test Labels Shape: {f_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (84470, 200, 1), Test Shape: (28177, 200, 1)\n",
      "Original Train Labels Shape: (84470, 23), Test Labels Shape: (28177, 23)\n",
      "Reduced Train Shape: (21117, 200, 1), Test Shape: (2817, 200, 1)\n",
      "Reduced Train Labels Shape: (21117, 23), Test Labels Shape: (2817, 23)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Stack and reshape the data\n",
    "f_X_train = np.vstack(f_X_train).reshape(-1, 200, 1)\n",
    "f_X_test = np.vstack(f_X_test).reshape(-1, 200, 1)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train_int = [char_to_int.get(char, -1) for char in f_y_train]\n",
    "y_test_int = [char_to_int.get(char, -1) for char in f_y_test]\n",
    "y_train_int = [y for y in y_train_int if y != -1]\n",
    "y_test_int = [y for y in y_test_int if y != -1]\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(char_to_int)\n",
    "f_y_train = to_categorical(y_train_int, num_classes=num_classes)\n",
    "f_y_test = to_categorical(y_test_int, num_classes=num_classes)\n",
    "\n",
    "# Print original shapes\n",
    "print(f\"Original Train Shape: {f_X_train.shape}, Test Shape: {f_X_test.shape}\")\n",
    "print(f\"Original Train Labels Shape: {f_y_train.shape}, Test Labels Shape: {f_y_test.shape}\")\n",
    "\n",
    "# Reduce dataset size to 1%\n",
    "def reduce_dataset_size(X, y, fraction=0.01):\n",
    "    num_samples = int(X.shape[0] * fraction)\n",
    "    indices = np.random.choice(X.shape[0], num_samples, replace=False)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Reduce training and testing data\n",
    "f_X_train, f_y_train = reduce_dataset_size(f_X_train, f_y_train, fraction=0.25)\n",
    "f_X_test, f_y_test = reduce_dataset_size(f_X_test, f_y_test, fraction=0.1)\n",
    "\n",
    "# Print reduced shapes\n",
    "print(f\"Reduced Train Shape: {f_X_train.shape}, Test Shape: {f_X_test.shape}\")\n",
    "print(f\"Reduced Train Labels Shape: {f_y_train.shape}, Test Labels Shape: {f_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"history\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGModel(nn.Module):\n",
    "    def __init__(self, config, num_classes, input_size=200):  # ✅ Explicit input size\n",
    "        super(ECGModel, self).__init__()\n",
    "\n",
    "        # Extract hyperparameters from config\n",
    "        feature_extractor = config[8]  # CNN (0) or RCNN (1)\n",
    "        sequence_model = config[9]  # BiLSTM (0) or GRU (1)\n",
    "        num_cnn_layers = int(config[0])\n",
    "        num_rnn_layers = int(config[1])\n",
    "        dropout = config[3]\n",
    "\n",
    "        # Ensure CNN filters, hidden size, and FC neurons follow power-of-2 convention\n",
    "        num_filters = max(32, 2 ** (int(config[4])))\n",
    "        hidden_size = max(64, 2 ** (int(config[10])))\n",
    "        fc_neurons = max(32, 2 ** (int(config[11])))\n",
    "\n",
    "        kernel_size = int(config[5])\n",
    "        stride = int(config[6])\n",
    "\n",
    "        # ✅ Set initial input size explicitly\n",
    "        self.initial_input_size = input_size  \n",
    "\n",
    "        # ✅ Feature Extractor (CNN)\n",
    "        layers = []\n",
    "        in_channels = 1  # First CNN layer expects 1D ECG input (batch, 1, time_steps)\n",
    "\n",
    "        # ✅ Dynamically apply CNN layers and adjust input size\n",
    "        for i in range(num_cnn_layers):\n",
    "            out_channels = max(16, num_filters // (2 ** i))  # Reduce channels gradually\n",
    "            layers.append(nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=1))\n",
    "            layers.append(nn.BatchNorm1d(out_channels))  # Batch normalization for stability\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))  # Dropout for regularization\n",
    "            in_channels = out_channels  # Update for next CNN layer\n",
    "\n",
    "            # ✅ Update input size correctly after each CNN layer\n",
    "            input_size = max(4, (input_size - kernel_size + 2 * 1) // stride + 1)  \n",
    "\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.final_cnn_output_size = input_size  # ✅ Store the shrunk size for RNN input\n",
    "        self.final_num_filters = out_channels  # ✅ Last CNN layer's channels\n",
    "\n",
    "        # ✅ If RCNN, apply LSTM immediately after CNN\n",
    "        if feature_extractor == 1:\n",
    "            self.rnn = nn.LSTM(input_size=self.final_num_filters, hidden_size=hidden_size, num_layers=num_rnn_layers, batch_first=True, dropout=dropout)\n",
    "        else:\n",
    "            self.rnn = None  # No extra LSTM if pure CNN is selected\n",
    "\n",
    "        # ✅ Sequence Model (RNN: BiLSTM or GRU)\n",
    "        if sequence_model == 0:\n",
    "            self.rnn_layer = nn.LSTM(input_size=self.final_num_filters, hidden_size=hidden_size, num_layers=num_rnn_layers, batch_first=True, dropout=dropout)\n",
    "        else:\n",
    "            self.rnn_layer = nn.GRU(input_size=self.final_num_filters, hidden_size=hidden_size, num_layers=num_rnn_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # ✅ Fully Connected Layers\n",
    "        self.fc = nn.Linear(hidden_size, fc_neurons)\n",
    "        self.output = nn.Linear(fc_neurons, num_classes)  # Final classification layer\n",
    "\n",
    "        # ✅ Weight Initialization\n",
    "        self.apply(self.init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ✅ Ensure input shape is correct\n",
    "        assert x.shape[-1] == self.initial_input_size, f\"Expected input size {self.initial_input_size}, but got {x.shape[-1]}\"\n",
    "\n",
    "        # ✅ Feature extraction (CNN)\n",
    "        x = self.feature_extractor(x)  # (batch, channels, time_steps)\n",
    "\n",
    "        # ✅ Ensure RNN gets correct input size\n",
    "        assert x.shape[-1] == self.final_cnn_output_size, f\"Expected RNN input size {self.final_cnn_output_size}, but got {x.shape[-1]}\"\n",
    "\n",
    "        # ✅ Permute CNN output for RNN (batch, channels, time_steps) → (batch, time_steps, features)\n",
    "        x = x.permute(0, 2, 1)  \n",
    "\n",
    "        # ✅ If RCNN (CNN + RNN), process through additional LSTM layer\n",
    "        if self.rnn is not None:\n",
    "            x, _ = self.rnn(x)\n",
    "\n",
    "        # ✅ Process through final sequence model (LSTM/GRU)\n",
    "        x, _ = self.rnn_layer(x)\n",
    "\n",
    "        # ✅ Take the last time step's output for classification\n",
    "        x = self.fc(x[:, -1, :])  \n",
    "        x = self.output(x)  \n",
    "        return x\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        \"\"\" Initialize weights for all layers \"\"\"\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv1d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        elif isinstance(m, nn.LSTM) or isinstance(m, nn.GRU):\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "                elif 'bias' in name:\n",
    "                    nn.init.constant_(param, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_filename(config):\n",
    "    \"\"\" Convert model config into a valid filename \"\"\"\n",
    "    formatted_config = \"_\".join([f\"{x:.4f}\" if isinstance(x, float) else str(x) for x in config])\n",
    "    formatted_config = re.sub(r'[^\\w\\-_]', '', formatted_config)  # Remove special characters\n",
    "    return formatted_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_latency(model, dataloader, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Measures average inference latency (in milliseconds) per sample.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_time = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:  # We only need inputs, not labels\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            # Start time measurement\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.synchronize()  # Ensure GPU operations are finished\n",
    "                start_time = time.time()\n",
    "            else:\n",
    "                start_time = time.perf_counter()\n",
    "\n",
    "            _ = model(inputs)  # Forward pass\n",
    "\n",
    "            # End time measurement\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "                end_time = time.time()\n",
    "            else:\n",
    "                end_time = time.perf_counter()\n",
    "\n",
    "            total_time += (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "            num_samples += batch_size\n",
    "\n",
    "    return total_time / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serializable(obj):\n",
    "    \"\"\" Converts NumPy arrays and other non-serializable objects to lists for JSON serialization \"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert NumPy array to a list\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]  # Recursively process lists\n",
    "    return obj  # Return normal values unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(config):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model using real ECG data.\n",
    "    \"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(config)\n",
    "    # Load preprocessed dataset (Ensure you have f_X_train, f_X_test, f_y_train, f_y_test)\n",
    "    X_train, X_test = torch.tensor(f_X_train, dtype=torch.float32), torch.tensor(f_X_test, dtype=torch.float32)\n",
    "    y_train, y_test = torch.tensor(f_y_train, dtype=torch.float32), torch.tensor(f_y_test, dtype=torch.float32)\n",
    "\n",
    "    # Reshape input to match PyTorch format: (batch, channels, time_steps)\n",
    "    X_train = X_train.permute(0, 2, 1)  # Convert from (batch, time_steps, 1) → (batch, 1, time_steps)\n",
    "    X_test = X_test.permute(0, 2, 1)\n",
    "\n",
    "    # Use batch size from config\n",
    "    batch_size = int(config[7]) if len(config) > 11 else 64\n",
    "    train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    num_classes = f_y_train.shape[1]\n",
    "    model = ECGModel(config, num_classes).to(device)\n",
    "\n",
    "    # Define loss function & optimizer with weighted loss for imbalance\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[2])\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            true_labels = torch.argmax(labels, dim=1).cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(true_labels)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    # Measure real inference latency\n",
    "    latency = measure_latency(model, test_loader, device)\n",
    "\n",
    "    # Define fitness score\n",
    "    fitness = accuracy - (latency / 100)\n",
    "\n",
    "    # Save model\n",
    "    model_name = f\"model_{format_filename(config)}.pt\"\n",
    "    torch.save(model.state_dict(), f\"models/{model_name}\")\n",
    "\n",
    "    # Save results\n",
    "    serializable_config = convert_to_serializable(config)\n",
    "\n",
    "    result = {\n",
    "        \"config\": serializable_config,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"latency\": latency,\n",
    "        \"fitness\": fitness\n",
    "    }\n",
    "    result_filename = f\"results/{model_name}.json\"\n",
    "    with open(result_filename, \"w\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    print(f\"✅Accuracy: {accuracy:.4f}, Latency: {latency:.2f}ms, Fitness: {fitness:.4f} | Model Saved: {model_name}\")\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space for the GA\n",
    "bounds = [\n",
    "    IntegerVar(lb=1, ub=5),         # 0: Number of CNN layers (Integer)\n",
    "    IntegerVar(lb=1, ub=5),         # 1: Number of RNN layers (Integer)\n",
    "    FloatVar(lb=0.0001, ub=0.01),   # 2: Learning rate (Float)\n",
    "    FloatVar(lb=0.1, ub=0.5),       # 3: Dropout rate (Float)\n",
    "    IntegerVar(lb=5, ub=8),         # 4: Number of filters in CNN (Integer)\n",
    "    IntegerVar(lb=3, ub=6),         # 5: Kernel size for CNN (Integer)\n",
    "    IntegerVar(lb=1, ub=3),         # 6: Stride for CNN (Integer)\n",
    "    IntegerVar(lb=4, ub=7),         # 7: Batch size (Integer)\n",
    "    IntegerVar(lb=0, ub=1),         # 8: CNN/RCNN (Integer: 0 = CNN, 1 = RCNN)\n",
    "    IntegerVar(lb=0, ub=1),         # 9: GRU/BiLSTM (Integer: 0 = BiLSTM, 1 = GRU)\n",
    "    IntegerVar(lb=6, ub=9),         # 10: Hidden size for RNN (Integer)\n",
    "    IntegerVar(lb=5, ub=8),         # 11: Fully connected layer neurons (Integer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Genetic Algorithm for Model Optimization...\n",
      "\n",
      "[1.00000000e+00 3.00000000e+00 7.94793848e-03 4.48172803e-01\n",
      " 7.00000000e+00 3.00000000e+00 1.00000000e+00 7.00000000e+00\n",
      " 0.00000000e+00 1.00000000e+00 9.00000000e+00 7.00000000e+00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRunning Genetic Algorithm for Model Optimization...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m ga_model \u001b[38;5;241m=\u001b[39m GA\u001b[38;5;241m.\u001b[39mBaseGA(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, pc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, pm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)  \u001b[38;5;66;03m# 10 generations, 5 models per generation\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m best_solution \u001b[38;5;241m=\u001b[39m \u001b[43mga_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract best architecture and fitness score\u001b[39;00m\n\u001b[0;32m     14\u001b[0m best_architecture \u001b[38;5;241m=\u001b[39m best_solution\u001b[38;5;241m.\u001b[39msolution\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\optimizer.py:223\u001b[0m, in \u001b[0;36mOptimizer.solve\u001b[1;34m(self, problem, mode, n_workers, termination, starting_solutions, seed)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msolve\u001b[39m(\u001b[38;5;28mself\u001b[39m, problem: Union[Dict, Problem] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m'\u001b[39m, n_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    203\u001b[0m           termination: Union[Dict, Termination] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, starting_solutions: Union[List, np\u001b[38;5;241m.\u001b[39mndarray, Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    204\u001b[0m           seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Agent:\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        problem: an instance of Problem class or a dictionary\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m        g_best: g_best, the best found agent, that hold the best solution and the best target. Access by: .g_best.solution, .g_best.target\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_problem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_mode_and_workers(mode, n_workers)\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_termination(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, termination, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\optimizer.py:157\u001b[0m, in \u001b[0;36mOptimizer.check_problem\u001b[1;34m(self, problem, seed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(problem) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m    156\u001b[0m     problem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m seed\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem \u001b[38;5;241m=\u001b[39m \u001b[43mProblem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproblem needs to be a dict or an instance of Problem class.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\utils\\problem.py:28\u001b[0m, in \u001b[0;36mProblem.__init__\u001b[1;34m(self, bounds, minmax, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_keyword_arguments(kwargs)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(bounds)\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__set_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to, log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_file)\u001b[38;5;241m.\u001b[39mcreate_logger(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m                             format_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m [line: \u001b[39m\u001b[38;5;132;01m%(lineno)d\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\utils\\problem.py:65\u001b[0m, in \u001b[0;36mProblem.__set_functions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m tested_solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_solution(encoded\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(tested_solution)\n\u001b[1;32m---> 65\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtested_solution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(result) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSUPPORTED_ARRAYS:\n\u001b[0;32m     67\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(result)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "Cell \u001b[1;32mIn[62], line 37\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m     34\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 37\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[58], line 80\u001b[0m, in \u001b[0;36mECGModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     77\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(x)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# ✅ Process through final sequence model (LSTM/GRU)\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# ✅ Take the last time step's output for classification\u001b[39;00m\n\u001b[0;32m     83\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:1139\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1139\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1142\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1143\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define problem dictionary for Mealpy\n",
    "problem_dict = {\n",
    "    \"obj_func\": train_and_evaluate,\n",
    "    \"bounds\": bounds,\n",
    "    \"minmax\": \"max\"  # We want to maximize the fitness function\n",
    "}\n",
    "\n",
    "# Run Genetic Algorithm optimization\n",
    "print(\"\\nRunning Genetic Algorithm for Model Optimization...\\n\")\n",
    "ga_model = GA.BaseGA(epoch=10, pop_size=5, pc=0.9, pm=0.05)  # 10 generations, 5 models per generation\n",
    "best_solution = ga_model.solve(problem_dict)\n",
    "\n",
    "# Extract best architecture and fitness score\n",
    "best_architecture = best_solution.solution\n",
    "best_fitness = best_solution.target.fitness\n",
    "\n",
    "# Save best model details\n",
    "best_model_info = {\n",
    "    \"best_architecture\": best_architecture,\n",
    "    \"best_fitness\": best_fitness\n",
    "}\n",
    "with open(\"results/best_model.json\", \"w\") as f:\n",
    "    json.dump(best_model_info, f, indent=4)\n",
    "\n",
    "# Print best model\n",
    "print(f\"\\n🏆 Best Model Configuration: {best_architecture}, Fitness Score: {best_fitness}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
