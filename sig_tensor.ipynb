{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import wfdb\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import json\n",
    "from mealpy.evolutionary_based.GA import BaseGA\n",
    "from mealpy.evolutionary_based import GA\n",
    "from mealpy import FloatVar\n",
    "from mealpy import IntegerVar\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from mealpy.swarm_based import PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path('C:/Users/vinay/Downloads/mit-bih-arrhythmia-database-1.0.0/mit-bih-arrhythmia-database-1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files=[]\n",
    "annot_files=[]\n",
    "for file in os.listdir(file_path):\n",
    "    if('.dat' in file):\n",
    "        data_files.append(file[:-4])\n",
    "    elif('.atr' in file):\n",
    "        annot_files.append(file[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+': 0, 'N': 1, 'A': 2, 'V': 3, '~': 4, '|': 5, 'Q': 6, '/': 7, 'f': 8, 'x': 9, 'F': 10, 'j': 11, 'L': 12, 'a': 13, 'J': 14, 'R': 15, '[': 16, '!': 17, ']': 18, 'E': 19, 'S': 20, '\"': 21, 'e': 22}\n"
     ]
    }
   ],
   "source": [
    "char_to_int = {}\n",
    "count = 0 \n",
    "\n",
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr') \n",
    "    \n",
    "    for symbol in annotation.symbol:\n",
    "        if symbol not in char_to_int: \n",
    "            char_to_int[symbol] = count\n",
    "            count += 1 \n",
    "\n",
    "print(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 {'+': 1, 'A': 33, 'N': 2239, 'V': 1} 2274 2274\n",
      "101 {'+': 1, 'A': 3, 'N': 1860, 'Q': 2, '|': 4, '~': 4} 1874 1874\n",
      "102 {'+': 5, '/': 2028, 'N': 99, 'V': 4, 'f': 56} 2192 2192\n",
      "103 {'+': 1, 'A': 2, 'N': 2082, '~': 6} 2091 2091\n",
      "104 {'+': 45, '/': 1380, 'N': 163, 'Q': 18, 'V': 2, 'f': 666, '~': 37} 2311 2311\n",
      "105 {'+': 1, 'N': 2526, 'Q': 5, 'V': 41, '|': 30, '~': 88} 2691 2691\n",
      "106 {'+': 41, 'N': 1507, 'V': 520, '~': 30} 2098 2098\n",
      "107 {'+': 1, '/': 2078, 'V': 59, '~': 2} 2140 2140\n",
      "108 {'+': 1, 'A': 4, 'F': 2, 'N': 1739, 'V': 17, 'j': 1, 'x': 11, '|': 8, '~': 41} 1824 1824\n",
      "109 {'+': 1, 'F': 2, 'L': 2492, 'V': 38, '~': 2} 2535 2535\n",
      "111 {'+': 1, 'L': 2123, 'V': 1, '~': 8} 2133 2133\n",
      "112 {'+': 1, 'A': 2, 'N': 2537, '~': 10} 2550 2550\n",
      "113 {'+': 1, 'N': 1789, 'a': 6} 1796 1796\n",
      "114 {'+': 3, 'A': 10, 'F': 4, 'J': 2, 'N': 1820, 'V': 43, '|': 1, '~': 7} 1890 1890\n",
      "115 {'+': 1, 'N': 1953, '|': 6, '~': 2} 1962 1962\n",
      "116 {'+': 1, 'A': 1, 'N': 2302, 'V': 109, '~': 8} 2421 2421\n",
      "117 {'+': 1, 'A': 1, 'N': 1534, '~': 3} 1539 1539\n",
      "118 {'+': 1, 'A': 96, 'R': 2166, 'V': 16, 'x': 10, '~': 12} 2301 2301\n",
      "119 {'+': 103, 'N': 1543, 'V': 444, '~': 4} 2094 2094\n",
      "121 {'+': 1, 'A': 1, 'N': 1861, 'V': 1, '~': 12} 1876 1876\n",
      "122 {'+': 1, 'N': 2476, '|': 2} 2479 2479\n",
      "123 {'+': 1, 'N': 1515, 'V': 3} 1519 1519\n",
      "124 {'+': 13, 'A': 2, 'F': 5, 'J': 29, 'R': 1531, 'V': 47, 'j': 5, '~': 2} 1634 1634\n",
      "200 {'+': 148, 'A': 30, 'F': 2, 'N': 1743, 'V': 826, '~': 43} 2792 2792\n",
      "201 {'+': 35, 'A': 30, 'F': 2, 'J': 1, 'N': 1625, 'V': 198, 'a': 97, 'j': 10, 'x': 37, '~': 4} 2039 2039\n",
      "202 {'+': 8, 'A': 36, 'F': 1, 'N': 2061, 'V': 19, 'a': 19, '|': 2} 2146 2146\n",
      "203 {'+': 45, 'F': 1, 'N': 2529, 'Q': 4, 'V': 444, 'a': 2, '|': 26, '~': 57} 3108 3108\n",
      "205 {'+': 13, 'A': 3, 'F': 11, 'N': 2571, 'V': 71, '|': 1, '~': 2} 2672 2672\n",
      "207 {'!': 472, '+': 24, 'A': 107, 'E': 105, 'L': 1457, 'R': 86, 'V': 105, '[': 6, ']': 6, '|': 2, '~': 15} 2385 2385\n",
      "208 {'+': 53, 'F': 373, 'N': 1586, 'Q': 2, 'S': 2, 'V': 992, '|': 8, '~': 24} 3040 3040\n",
      "209 {'+': 21, 'A': 383, 'N': 2621, 'V': 1, '|': 7, '~': 19} 3052 3052\n",
      "210 {'+': 17, 'E': 1, 'F': 10, 'N': 2423, 'V': 194, 'a': 22, '|': 1, '~': 17} 2685 2685\n",
      "212 {'+': 1, 'N': 923, 'R': 1825, '|': 1, '~': 13} 2763 2763\n",
      "213 {'+': 43, 'A': 25, 'F': 362, 'N': 2641, 'V': 220, 'a': 3} 3294 3294\n",
      "214 {'\"': 1, '+': 25, 'F': 1, 'L': 2003, 'Q': 2, 'V': 256, '|': 5, '~': 4} 2297 2297\n",
      "215 {'\"': 2, '+': 5, 'A': 3, 'F': 1, 'N': 3195, 'V': 164, '~': 30} 3400 3400\n",
      "217 {'+': 67, '/': 1542, 'N': 244, 'V': 162, 'f': 260, '|': 1, '~': 4} 2280 2280\n",
      "219 {'\"': 4, '+': 21, 'A': 7, 'F': 1, 'N': 2082, 'V': 64, 'x': 133} 2312 2312\n",
      "220 {'+': 17, 'A': 94, 'N': 1954, '~': 4} 2069 2069\n",
      "221 {'+': 23, 'N': 2031, 'V': 396, '~': 12} 2462 2462\n",
      "222 {'+': 136, 'A': 208, 'J': 1, 'N': 2062, 'j': 212, '~': 15} 2634 2634\n",
      "223 {'+': 28, 'A': 72, 'F': 14, 'N': 2029, 'V': 473, 'a': 1, 'e': 16, '~': 10} 2643 2643\n",
      "228 {'\"': 3, '+': 41, 'A': 3, 'N': 1688, 'V': 362, '|': 24, '~': 20} 2141 2141\n",
      "230 {'+': 207, 'N': 2255, 'V': 1, '|': 1, '~': 2} 2466 2466\n",
      "231 {'\"': 427, '+': 11, 'A': 1, 'N': 314, 'R': 1254, 'V': 2, 'x': 2} 2011 2011\n",
      "232 {'+': 1, 'A': 1382, 'R': 397, 'j': 1, '~': 35} 1816 1816\n",
      "233 {'+': 71, 'A': 7, 'F': 11, 'N': 2230, 'V': 831, '|': 2} 3152 3152\n",
      "234 {'+': 3, 'J': 50, 'N': 2700, 'V': 3, '~': 8} 2764 2764\n"
     ]
    }
   ],
   "source": [
    "for file in annot_files:\n",
    "    path_file = os.path.join(file_path, file)\n",
    "    annotation = wfdb.rdann(path_file, 'atr')\n",
    "    unique, counts = np.unique(annotation.symbol, return_counts=True)\n",
    "    print(file, dict(zip(unique, counts)), counts.sum(), len(annotation.sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(48):\n",
    "    data, field = wfdb.rdsamp(os.path.join(file_path, data_files[i]))\n",
    "    data = data[:, 0]\n",
    "    \n",
    "    annot = wfdb.rdann(os.path.join(file_path, annot_files[i]), 'atr')\n",
    "    segmented_signals = [data[max(0, peak - 100):min(len(data), peak + 100)] for peak in annot.sample]\n",
    "    \n",
    "    segmented_array = np.array([\n",
    "        np.pad(signal, (0, 200 - len(signal)), mode='edge') if len(signal) < 200 else signal\n",
    "        for signal in segmented_signals\n",
    "    ])\n",
    "    \n",
    "    labels = annot.symbol[:len(segmented_array)]  \n",
    "\n",
    "    all_signals.append(segmented_array)\n",
    "    all_labels.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_X_train, f_X_test, f_y_train, f_y_test = [], [], [], []\n",
    "for i in range(48):\n",
    "    X = np.array(all_signals[i]).reshape(-1, 200)\n",
    "    y = np.array(all_labels[i]).flatten()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=42\n",
    "    )\n",
    "    f_X_train.append(X_train)\n",
    "    f_X_test.append(X_test)\n",
    "    f_y_train.extend(y_train)  \n",
    "    f_y_test.extend(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Shape: (84470, 200, 1), Test Shape: (28177, 200, 1)\n",
      "Original Train Labels Shape: (84470, 23), Test Labels Shape: (28177, 23)\n",
      "Reduced Train Shape: (12670, 200, 1), Test Shape: (2817, 200, 1)\n",
      "Reduced Train Labels Shape: (12670, 23), Test Labels Shape: (2817, 23)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Stack and reshape the data\n",
    "f_X_train = np.vstack(f_X_train).reshape(-1, 200, 1)\n",
    "f_X_test = np.vstack(f_X_test).reshape(-1, 200, 1)\n",
    "\n",
    "# Convert labels to integers\n",
    "y_train_int = [char_to_int.get(char, -1) for char in f_y_train]\n",
    "y_test_int = [char_to_int.get(char, -1) for char in f_y_test]\n",
    "y_train_int = [y for y in y_train_int if y != -1]\n",
    "y_test_int = [y for y in y_test_int if y != -1]\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = len(char_to_int)\n",
    "f_y_train = to_categorical(y_train_int, num_classes=num_classes)\n",
    "f_y_test = to_categorical(y_test_int, num_classes=num_classes)\n",
    "\n",
    "# Print original shapes\n",
    "print(f\"Original Train Shape: {f_X_train.shape}, Test Shape: {f_X_test.shape}\")\n",
    "print(f\"Original Train Labels Shape: {f_y_train.shape}, Test Labels Shape: {f_y_test.shape}\")\n",
    "\n",
    "# Reduce dataset size to 1%\n",
    "def reduce_dataset_size(X, y, fraction=0.01):\n",
    "    num_samples = int(X.shape[0] * fraction)\n",
    "    indices = np.random.choice(X.shape[0], num_samples, replace=False)\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "# Reduce training and testing data\n",
    "f_X_train, f_y_train = reduce_dataset_size(f_X_train, f_y_train, fraction=0.15)\n",
    "f_X_test, f_y_test = reduce_dataset_size(f_X_test, f_y_test, fraction=0.1)\n",
    "\n",
    "# Print reduced shapes\n",
    "print(f\"Reduced Train Shape: {f_X_train.shape}, Test Shape: {f_X_test.shape}\")\n",
    "print(f\"Reduced Train Labels Shape: {f_y_train.shape}, Test Labels Shape: {f_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "os.makedirs(\"history\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(tf.keras.Model):\n",
    "    def __init__(self, config, num_classes):\n",
    "        super(HybridModel, self).__init__()\n",
    "        \n",
    "        # Extract hyperparameters from config\n",
    "        feature_extractor = config[8]  # CNN (0) or RCNN (1)\n",
    "        sequence_model = config[9]  # BiLSTM (0) or GRU (1)\n",
    "        num_cnn_layers = int(config[0])\n",
    "        num_rnn_layers = int(config[1])\n",
    "        dropout = config[3]\n",
    "        initial_filters = 2 ** int(config[4])  # Convert to power of 2\n",
    "        initial_kernel = int(config[5])  # Initial kernel size\n",
    "        stride = int(config[6])\n",
    "        initial_hidden_size = 2 ** int(config[10])  # Convert to power of 2\n",
    "        fc_neurons = 2 ** int(config[11])  # Fully connected neurons (power of 2)\n",
    "\n",
    "        # Input Layer\n",
    "        input_layer = layers.Input(shape=(200, 1))  # Default input size of 200\n",
    "        x = input_layer\n",
    "\n",
    "        # CNN Feature Extractor (Filters Increase, Kernel Size Decreases)\n",
    "        num_filters = initial_filters\n",
    "        kernel_size = initial_kernel\n",
    "        for _ in range(num_cnn_layers):\n",
    "            x = layers.Conv1D(filters=num_filters, kernel_size=kernel_size, strides=stride, padding='same')(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.ReLU()(x)\n",
    "            x = layers.Dropout(dropout)(x)\n",
    "\n",
    "            num_filters = min(256, num_filters * 2)  # Filters Increase (Cap at 256)\n",
    "            kernel_size = max(3, kernel_size - 1)  # Kernel Size Decreases (Min 3)\n",
    "\n",
    "        # Handle RCNN (CNN + RNN)\n",
    "        if feature_extractor == 1:\n",
    "            x = layers.Reshape((-1, num_filters // 2))(x)  # Flatten for RNN\n",
    "            hidden_size = initial_hidden_size\n",
    "            for _ in range(num_rnn_layers):\n",
    "                if sequence_model == 0:\n",
    "                    x = layers.Bidirectional(layers.LSTM(hidden_size, return_sequences=True))(x)\n",
    "                else:\n",
    "                    x = layers.Bidirectional(layers.GRU(hidden_size, return_sequences=True))(x)\n",
    "                x = layers.Dropout(dropout)(x)\n",
    "                hidden_size = max(16, hidden_size // 2)  # Hidden Size Decreases (Min 16)\n",
    "\n",
    "        # Sequence Model (BiLSTM or GRU) (Hidden Size Decreases)\n",
    "        hidden_size = initial_hidden_size\n",
    "        for _ in range(num_rnn_layers):\n",
    "            if sequence_model == 0:\n",
    "                x = layers.Bidirectional(layers.LSTM(hidden_size, return_sequences=True))(x)\n",
    "            else:\n",
    "                x = layers.Bidirectional(layers.GRU(hidden_size, return_sequences=True))(x)\n",
    "            x = layers.Dropout(dropout)(x)\n",
    "            hidden_size = max(16, hidden_size // 2)  # Hidden Size Decreases\n",
    "\n",
    "        # Global Pooling & Fully Connected Layer\n",
    "        x = layers.GlobalAveragePooling1D()(x)\n",
    "        x = layers.Dense(fc_neurons, activation='relu')(x)\n",
    "        output_layer = layers.Dense(num_classes, activation='softmax')(x)  # Multi-class classification\n",
    "        \n",
    "        self.model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.model(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_filename(config):\n",
    "    \"\"\" Convert model config into a valid filename \"\"\"\n",
    "    formatted_config = \"_\".join([f\"{x:.4f}\" if isinstance(x, float) else str(x) for x in config])\n",
    "    formatted_config = re.sub(r'[^\\w\\-_]', '', formatted_config)  # Remove special characters\n",
    "    return formatted_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serializable(obj):\n",
    "    \"\"\" Converts NumPy arrays and other non-serializable objects to lists for JSON serialization \"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert NumPy array to a list\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(item) for item in obj]  # Recursively process lists\n",
    "    return obj  # Return normal values unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already preprocessed and prepared your dataset:\n",
    "# f_X_train, f_X_test, f_y_train, f_y_test\n",
    "\n",
    "def measure_latency(model, X_test, batch_size=64):\n",
    "    \"\"\" Measure the time it takes for the model to perform inference on the test data \"\"\"\n",
    "    start_time = time.time()\n",
    "    model.predict(X_test, batch_size=batch_size)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time\n",
    "\n",
    "def train_and_evaluate(config):\n",
    "    \"\"\"\n",
    "    Train and evaluate the model using real ECG data.\n",
    "    \"\"\"\n",
    "    # TensorFlow does not need to worry about device assignments (CUDA is abstracted)\n",
    "    # Assuming f_X_train and f_X_test are pre-processed numpy arrays\n",
    "    X_train, X_test = f_X_train, f_X_test\n",
    "    y_train, y_test = f_y_train, f_y_test\n",
    "    \n",
    "    # Use batch size from config (adjusting it to power of 2 for optimization)\n",
    "    batch_size = 2**(int(config[7])) if len(config) > 7 else 64\n",
    "    num_classes = y_train.shape[1]  # Number of classes\n",
    "\n",
    "    # Initialize model\n",
    "    model = HybridModel(config, num_classes)  # Use the HybridModel class\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config[2]), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train model\n",
    "    num_epochs = 10\n",
    "    history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "    # Evaluate on test set\n",
    "    accuracy = accuracy_score(y_test.argmax(axis=1), model.predict(X_test).argmax(axis=1))\n",
    "\n",
    "    # Measure real inference latency\n",
    "    latency = measure_latency(model, X_test, batch_size)\n",
    "\n",
    "    # Define fitness score (maximize accuracy, minimize latency)\n",
    "    fitness = accuracy - (latency / 100)\n",
    "\n",
    "    # Save model\n",
    "    model_name = f\"model_{format_filename(config)}.h5\"\n",
    "    model.save(f\"models/{model_name}\")\n",
    "\n",
    "    # Save results\n",
    "    serializable_config = convert_to_serializable(config)\n",
    "\n",
    "    result = {\n",
    "        \"config\": serializable_config,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"latency\": latency,\n",
    "        \"fitness\": fitness\n",
    "    }\n",
    "    result_filename = f\"results/{model_name}.json\"\n",
    "    with open(result_filename, \"w\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "\n",
    "    print(f\"‚úÖ Config: {serializable_config} -> Accuracy: {accuracy:.4f}, Latency: {latency:.2f}ms, Fitness: {fitness:.4f} | Model Saved: {model_name}\")\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [\n",
    "    IntegerVar(lb=1, ub=5),         # 0: Number of CNN layers (Integer)\n",
    "    IntegerVar(lb=1, ub=5),         # 1: Number of RNN layers (Integer)\n",
    "    FloatVar(lb=0.0001, ub=0.01),   # 2: Learning rate (Float)\n",
    "    FloatVar(lb=0.1, ub=0.5),       # 3: Dropout rate (Float)\n",
    "    IntegerVar(lb=5, ub=8),         # 4: Number of filters in CNN (Integer)\n",
    "    IntegerVar(lb=3, ub=6),         # 5: Kernel size for CNN (Integer)\n",
    "    IntegerVar(lb=1, ub=3),         # 6: Stride for CNN (Integer)\n",
    "    IntegerVar(lb=4, ub=7),         # 7: Batch size (Integer)\n",
    "    IntegerVar(lb=0, ub=1),         # 8: CNN/RCNN (Integer: 0 = CNN, 1 = RCNN)\n",
    "    IntegerVar(lb=0, ub=1),         # 9: GRU/BiLSTM (Integer: 0 = BiLSTM, 1 = GRU)\n",
    "    IntegerVar(lb=6, ub=9),         # 10: Hidden size for RNN (Integer)\n",
    "    IntegerVar(lb=5, ub=8),         # 11: Fully connected layer neurons (Integer)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Genetic Algorithm for Model Optimization...\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please set at least one stopping condition with parameter 'max_epoch' or 'max_fe' or 'max_time' or 'max_early_stop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m ga_model \u001b[38;5;241m=\u001b[39m GA\u001b[38;5;241m.\u001b[39mBaseGA(epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, pc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, pm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)  \u001b[38;5;66;03m# Set a large epoch value\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Define early stopping with patience=3\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Solve the problem with early stopping\u001b[39;00m\n\u001b[0;32m     45\u001b[0m best_solution \u001b[38;5;241m=\u001b[39m ga_model\u001b[38;5;241m.\u001b[39msolve(problem_dict, termination\u001b[38;5;241m=\u001b[39mearly_stopping)\n",
      "Cell \u001b[1;32mIn[41], line 7\u001b[0m, in \u001b[0;36mEarlyStopping.__init__\u001b[1;34m(self, patience)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience \u001b[38;5;241m=\u001b[39m patience\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\utils\\termination.py:68\u001b[0m, in \u001b[0;36mTermination.__init__\u001b[1;34m(self, max_epoch, max_fe, max_time, max_early_stop, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m Validator(log_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTermination\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__set_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_fe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_early_stop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger \u001b[38;5;241m=\u001b[39m Logger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_to, log_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_file)\u001b[38;5;241m.\u001b[39mcreate_logger(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m                             format_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m [line: \u001b[39m\u001b[38;5;132;01m%(lineno)d\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mpropagate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mealpy\\utils\\termination.py:83\u001b[0m, in \u001b[0;36mTermination.__set_condition\u001b[1;34m(self, max_epoch, max_fe, max_time, max_early_stop)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__set_condition\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_epoch, max_fe, max_time, max_early_stop):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (max_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (max_fe \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (max_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (max_early_stop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 83\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set at least one stopping condition with parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_fe\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_time\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_early_stop\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m max_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Please set at least one stopping condition with parameter 'max_epoch' or 'max_fe' or 'max_time' or 'max_early_stop'"
     ]
    }
   ],
   "source": [
    "# Define problem dictionary for Mealpy\n",
    "problem_dict = {\n",
    "    \"obj_func\": train_and_evaluate,\n",
    "    \"bounds\": bounds,\n",
    "    \"minmax\": \"max\"  # We want to maximize the fitness function\n",
    "}\n",
    "\n",
    "# Run Genetic Algorithm optimization\n",
    "print(\"\\nRunning Genetic Algorithm for Model Optimization...\\n\")\n",
    "ga_model = GA.BaseGA(epoch=10, pop_size=5, pc=0.9, pm=0.05)  # 10 generations, 5 models per generation\n",
    "best_solution = ga_model.solve(problem_dict)\n",
    "\n",
    "# Extract best architecture and fitness score\n",
    "best_architecture = best_solution.solution\n",
    "best_fitness = best_solution.target.fitness\n",
    "\n",
    "# Save best model details\n",
    "best_model_info = {\n",
    "    \"best_architecture\": best_architecture,\n",
    "    \"best_fitness\": best_fitness\n",
    "}\n",
    "with open(\"results/best_model.json\", \"w\") as f:\n",
    "    json.dump(best_model_info, f, indent=4)\n",
    "\n",
    "# Print best model\n",
    "print(f\"\\nüèÜ Best Model Configuration: {best_architecture}, Fitness Score: {best_fitness}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
